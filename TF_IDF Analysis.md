In order to conduct a proper TF_IDF analysis, and retrieve the important, unique, and relevant terms in the title of our articles, we coded two different algorithms to calculate words frequencies. Both of the algorithms had the following excluded key words: "alien", "romulus", "substance", "smile", "venom", "speak", "evil." This was done since the title for our movies are what we queried for when finding articles and would obviously top all of the TF_IDF scores if not removed. 

The first algorithm we created extracted the TF_IDF scores for all of our articles cumulatively (all 502). We pulled the top 20 most frequent words, and used the formula learned in class to calculate a TF_IDF score and ranking for all 20 words. Once we had extracted our criteria, we turned to matplotlib to help build a bar graph, sorted from highest to lowest, to show our most significant words. The reason for the sorting method was to help the viewer easily determine importance in a consistent order, and make terms comparison straightforward. 

The second algorithm, was a more specialized, targeting each individual category created from our typology and building TF_IDF scores for the top 20 words under each one. We separated our data by having the algorithm only pull articles under specific annotation categories. Otherwise the process was very similar to our first algorithm with the same excluded words and formula to determine our TF_IDF scores. Once insights from each individual category (8 total) were pulled, matplotlib was used to create bar graphs, sorted highest to for the unique terms. Although with a significantly smaller data set the TF_IDF scores were much lower than our first algorithm.